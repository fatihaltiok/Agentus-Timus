# agent/developer_agent_v2.py
# -*- coding: utf-8 -*-
"""
Verbesserter Developer Agent (D.A.V.E. v2) mit:
- Multi-Tool Support (nicht nur implement_feature)
- Code-Validierung (Syntax, Style, Tests)
- Projekt-Kontext-Sammlung
- LLM beh√§lt Kontrolle (kein automatisches Schreiben)
- Fehler-Recovery Strategien
- Dynamischer System-Prompt
"""
import logging
import os
import json
import textwrap
import requests
import sys
import re
import ast
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List

# -----------------------------------------------------------------------------
# Pfade & Module
# -----------------------------------------------------------------------------
CURRENT_SCRIPT_PATH = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_SCRIPT_PATH.parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# -----------------------------------------------------------------------------
# Konfiguration & Clients
# -----------------------------------------------------------------------------
from dotenv import load_dotenv
from openai import OpenAI
from utils.openai_compat import prepare_openai_params

# Shared Utilities
from agent.shared.mcp_client import MCPClient as _SharedMCPClient
from agent.shared.action_parser import parse_action as _shared_parse_action

load_dotenv(dotenv_path=PROJECT_ROOT / ".env")

MCP_URL = os.getenv("MCP_URL", "http://127.0.0.1:5000")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
TEXT_MODEL = os.getenv("MAIN_LLM_MODEL", "gpt-5")
REQUIRE_INCEPTION = os.getenv("REQUIRE_INCEPTION", "1") == "1"
DEBUG = os.getenv("DEV_AGENT_DEBUG", "1") == "1"

if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY fehlt in der Umgebung.")

client = OpenAI(api_key=OPENAI_API_KEY)

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
logger = logging.getLogger("developer_agent_v2")
if not logger.hasHandlers():
    handler = logging.StreamHandler(sys.stdout)
    fmt = "%(asctime)s | %(name)s | %(levelname)s | %(message)s"
    handler.setFormatter(logging.Formatter(fmt))
    logger.addHandler(handler)
logger.setLevel(logging.DEBUG if DEBUG else logging.INFO)

# -----------------------------------------------------------------------------
# Erlaubte Tools (Multi-Tool Support)
# -----------------------------------------------------------------------------
ALLOWED_TOOLS = [
    "implement_feature",      # Code generieren (Inception)
    "generate_and_integrate", # Alternative Code-Generierung
    "read_file_content",      # Dateien lesen f√ºr Kontext
    "list_agent_files",       # Projektstruktur analysieren
    "write_file",             # Datei schreiben (nach Validierung!)
    "run_tests",              # Tests ausf√ºhren
    "search_web",             # Dokumentation suchen
    "remember",               # Kontext merken
    "recall",                 # Kontext abrufen
]

# -----------------------------------------------------------------------------
# Kontext-Sammlung
# -----------------------------------------------------------------------------
def gather_project_context(dest_folder: str) -> str:
    """
    Sammelt umfassenden Projekt-Kontext f√ºr bessere Code-Generierung.

    Returns:
        Formatierter String mit Projektstruktur, Dependencies, etc.
    """
    context_parts = []

    try:
        # 1. Projektstruktur
        # list_agent_files nimmt nur 'subfolder' Parameter (tools/agent/server/skills)
        # Versuche mehrere Ordner f√ºr besseren Kontext
        all_files = []
        for folder in ["agent", "tools", "skills"]:
            structure = call_tool("list_agent_files", {"subfolder": folder})
            if isinstance(structure, dict) and not structure.get("error"):
                files = structure.get("files", [])
                all_files.extend(files)

        if all_files:
            context_parts.append(f"## Projektstruktur ({len(all_files)} Python-Dateien):")
            context_parts.append("\n".join(f"  - {f}" for f in all_files[:10]))
            if len(all_files) > 10:
                context_parts.append(f"  ... und {len(all_files) - 10} weitere")

        # 2. Dependencies (requirements.txt)
        req_path = f"{dest_folder}/requirements.txt"
        deps = call_tool("read_file_content", {"path": req_path})
        if isinstance(deps, dict) and not deps.get("error"):
            content = deps.get("content", "")
            if content:
                lines = [l.strip() for l in content.split("\n") if l.strip() and not l.startswith("#")]
                context_parts.append(f"\n## Dependencies ({len(lines)} Packages):")
                context_parts.append("\n".join(f"  - {l}" for l in lines[:8]))
                if len(lines) > 8:
                    context_parts.append(f"  ... und {len(lines) - 8} weitere")

        # 3. README oder Setup-Anweisungen
        readme_files = ["README.md", "README.txt", "setup_instructions.md"]
        for readme_file in readme_files:
            readme_path = f"{dest_folder}/{readme_file}"
            readme = call_tool("read_file_content", {"path": readme_path})
            if isinstance(readme, dict) and not readme.get("error"):
                content = readme.get("content", "")[:500]  # Erste 500 Zeichen
                if content:
                    context_parts.append(f"\n## Projekt-Beschreibung ({readme_file}):")
                    context_parts.append(content)
                break

        if context_parts:
            return "\n".join(context_parts)
        else:
            return f"Neues Projekt im Ordner: {dest_folder}"

    except Exception as e:
        logger.warning(f"Fehler bei Kontext-Sammlung: {e}")
        return f"Projekt-Ordner: {dest_folder}"


def detect_coding_style(dest_folder: str) -> str:
    """
    Erkennt den Coding-Style aus Konfigurationsdateien.

    Returns:
        Style-Beschreibung (z.B. "PEP8 + Black")
    """
    style_indicators = []

    # Pr√ºfe auf Black
    pyproject = call_tool("read_file_content", {"path": f"{dest_folder}/pyproject.toml"})
    if isinstance(pyproject, dict) and not pyproject.get("error"):
        content = pyproject.get("content", "")
        if "[tool.black]" in content:
            style_indicators.append("Black")

    # Pr√ºfe auf Ruff
    if isinstance(pyproject, dict) and not pyproject.get("error"):
        content = pyproject.get("content", "")
        if "[tool.ruff]" in content:
            style_indicators.append("Ruff")

    # Standard ist PEP8
    if not style_indicators:
        return "PEP8"

    return "PEP8 + " + " + ".join(style_indicators)


def find_related_files(dest_folder: str, target_file: str, max_files: int = 3) -> List[str]:
    """
    Findet verwandte Dateien im Projekt f√ºr besseren Kontext.

    Strategie:
    1. Dateien im gleichen Verzeichnis (gleicher Modul-Kontext)
    2. __init__.py im gleichen Package
    3. Dateien mit √§hnlichem Namen
    4. H√§ufig importierte Module (utils, base, config)

    Args:
        dest_folder: Projekt-Ordner
        target_file: Ziel-Datei f√ºr die Code generiert wird
        max_files: Maximale Anzahl Context-Dateien

    Returns:
        Liste von Dateipfaden (relativ zum dest_folder)
    """
    related = []
    target_path = Path(target_file)

    try:
        # 1. __init__.py im gleichen Verzeichnis (wichtig f√ºr Package-Struktur)
        if target_path.parent != Path("."):
            init_file = str(target_path.parent / "__init__.py")
            init_full = Path(dest_folder) / init_file
            if init_full.exists() and init_file != target_file:
                related.append(init_file)

        # 2. Dateien im gleichen Verzeichnis
        if target_path.parent != Path("."):
            sibling_dir = Path(dest_folder) / target_path.parent
            if sibling_dir.exists() and sibling_dir.is_dir():
                for sibling in sibling_dir.glob("*.py"):
                    rel_path = str(sibling.relative_to(dest_folder))
                    if rel_path != target_file and rel_path not in related:
                        related.append(rel_path)
                        if len(related) >= max_files:
                            break

        # 3. H√§ufig genutzte Module (utils, base, config, constants)
        if len(related) < max_files:
            common_names = ["utils.py", "base.py", "config.py", "constants.py", "settings.py"]
            for common in common_names:
                common_path = Path(dest_folder) / common
                if common_path.exists() and common != target_file and common not in related:
                    related.append(common)
                    if len(related) >= max_files:
                        break

        # 4. Dateien mit √§hnlichem Pr√§fix (z.B. user_model.py f√ºr user_controller.py)
        if len(related) < max_files:
            target_stem = target_path.stem
            prefix = target_stem.split("_")[0] if "_" in target_stem else target_stem[:4]

            for py_file in Path(dest_folder).rglob("*.py"):
                if len(related) >= max_files:
                    break
                rel_path = str(py_file.relative_to(dest_folder))
                if rel_path != target_file and rel_path not in related:
                    if py_file.stem.startswith(prefix):
                        related.append(rel_path)

        logger.info(f"üìö Context-Dateien gefunden: {related}")
        return related[:max_files]

    except Exception as e:
        logger.warning(f"Fehler bei find_related_files: {e}")
        return []


# -----------------------------------------------------------------------------
# Code-Validierung
# -----------------------------------------------------------------------------
def validate_python_syntax(code: str) -> Tuple[bool, str]:
    """
    Validiert Python-Syntax mit AST.

    Returns:
        (valid, error_message)
    """
    try:
        ast.parse(code)
        return True, "‚úÖ Syntax valid"
    except SyntaxError as e:
        return False, f"Syntax-Fehler in Zeile {e.lineno}: {e.msg}"
    except Exception as e:
        return False, f"Parsing-Fehler: {str(e)}"


def validate_code(code: str, file_path: str, dest_folder: str) -> Dict[str, Any]:
    """
    Umfassende Code-Validierung.

    Returns:
        Dict mit validation_status, errors, warnings
    """
    result = {
        "valid": True,
        "errors": [],
        "warnings": [],
        "checks": {}
    }

    # 1. Syntax-Check
    syntax_valid, syntax_msg = validate_python_syntax(code)
    result["checks"]["syntax"] = syntax_msg
    if not syntax_valid:
        result["valid"] = False
        result["errors"].append(syntax_msg)

    # 2. Basic Style-Checks (einfache Pr√ºfungen)
    lines = code.split("\n")

    # Pr√ºfe auf zu lange Zeilen (PEP8: 79 Zeichen)
    long_lines = [i+1 for i, line in enumerate(lines) if len(line) > 88]  # Black Standard: 88
    if long_lines:
        result["warnings"].append(f"Zeilen zu lang (>88): {long_lines[:5]}")

    # Pr√ºfe auf fehlende Docstrings bei Funktionen
    if "def " in code:
        funcs_without_docs = []
        in_func = False
        func_name = ""
        for i, line in enumerate(lines):
            if line.strip().startswith("def ") and not line.strip().startswith("def _"):
                in_func = True
                func_name = line.split("def ")[1].split("(")[0]
            elif in_func and i+1 < len(lines):
                next_line = lines[i+1].strip()
                if not next_line.startswith('"""') and not next_line.startswith("'''"):
                    funcs_without_docs.append(func_name)
                in_func = False

        if funcs_without_docs:
            result["warnings"].append(f"Funktionen ohne Docstring: {funcs_without_docs[:3]}")

    # 3. Pr√ºfe auf gef√§hrliche Patterns
    dangerous_patterns = [
        ("eval(", "Nutzung von eval() ist unsicher"),
        ("exec(", "Nutzung von exec() ist unsicher"),
        ("__import__", "Dynamischer Import kann problematisch sein"),
    ]

    for pattern, warning in dangerous_patterns:
        if pattern in code:
            result["warnings"].append(warning)

    result["checks"]["style"] = f"‚úÖ {len(result['warnings'])} Warnungen"

    return result


# -----------------------------------------------------------------------------
# Dynamischer System-Prompt
# -----------------------------------------------------------------------------
def build_system_prompt(dest_folder: str) -> str:
    """
    Erstellt projekt-spezifischen System-Prompt.
    """
    project_context = gather_project_context(dest_folder)
    coding_style = detect_coding_style(dest_folder)

    tools_list = "\n".join([f"  - {tool}" for tool in ALLOWED_TOOLS])

    return f"""Du bist D.A.V.E. v2, ein verbesserter Developer-Agent.

PROJEKT-KONTEXT:
{project_context}

CODING STYLE: {coding_style}
- Befolge {coding_style} Konventionen strikt
- Nutze Type Hints (Python 3.10+)
- Docstrings f√ºr alle √∂ffentlichen Funktionen
- Comprehensive Error Handling

VERF√úGBARE TOOLS:
{tools_list}

TOOL-PARAMETER WICHTIG:
- list_agent_files: Nimmt nur "subfolder" Parameter (Werte: "tools", "agent", "server", "skills")
  Beispiel: {{"method": "list_agent_files", "params": {{"subfolder": "agent"}}}}
- read_file_content: Nimmt nur "path" Parameter (relativer Pfad zum Projekt-Root)
  Beispiel: {{"method": "read_file_content", "params": {{"path": "agent/developer_agent.py"}}}}

WICHTIGE REGELN:
1. Sammle IMMER zuerst Kontext (read_file_content, list_agent_files)
2. Validiere Code BEVOR du schreibst (du bekommst Validation-Feedback)
3. Bei Fehlern: Analysiere und versuche alternative Ans√§tze
4. Nutze remember/recall f√ºr wichtige Informationen
5. Bei Unsicherheit: Mehr Kontext sammeln oder Dokumentation suchen

WORKFLOW (schrittweise!):
1. **Kontext sammeln**: read_file_content f√ºr √§hnliche Dateien, list_agent_files f√ºr Struktur
2. **Code generieren**: implement_feature mit vollst√§ndiger Spezifikation
   - WICHTIG: Nutze "context_files" Parameter f√ºr verwandte Dateien!
   - Format: {{"instruction": "...", "file_paths": ["target.py"], "context_files": ["related.py", "utils.py"]}}
3. **Validierung erhalten**: System validiert automatisch (Syntax, Style)
4. **Bei Validation OK**: Nutze write_file zum Speichern
5. **Bei Validation Fehler**: √úberarbeite basierend auf Feedback
6. **Finalisieren**: Nach erfolgreichem Schreiben

IMPLEMENT_FEATURE TOOL DETAILS:
- Parameter:
  * instruction: Detaillierte Code-Anweisung
  * file_paths: Liste der Ziel-Dateien (wird generiert)
  * context_files: [OPTIONAL] Liste verwandter Dateien f√ºr besseren Kontext
- Beispiel:
  {{"method": "implement_feature", "params": {{
    "instruction": "Create User model with email validation",
    "file_paths": ["models/user.py"],
    "context_files": ["models/__init__.py", "utils/validators.py"]
  }}}}

ANTWORTFORMAT (exakt eins pro Runde):
Thought: <kurzer Plan, was du als n√§chstes tust>
Action: {{"method": "tool_name", "params": {{...}}}}

ODER (nur nach erfolgreicher Fertigstellung):
Thought: Aufgabe abgeschlossen
Final Answer: <Zusammenfassung was gemacht wurde>

BEISPIEL-WORKFLOW:
```
# Schritt 1: Kontext - Projektstruktur
Thought: Ich pr√ºfe zun√§chst die Projektstruktur
Action: {{"method": "list_agent_files", "params": {{"subfolder": "agent"}}}}

# Schritt 2: Verwandte Dateien lesen (f√ºr context_files)
Thought: Ich lese verwandte Dateien um besseren Kontext zu haben
Action: {{"method": "read_file_content", "params": {{"path": "models/__init__.py"}}}}

# Schritt 3: Code generieren MIT context_files
Thought: Ich generiere den Code mit Kontext aus verwandten Dateien
Action: {{"method": "implement_feature", "params": {{
  "instruction": "Create User model with email validation",
  "file_paths": ["models/user.py"],
  "context_files": ["models/__init__.py", "utils/validators.py"]
}}}}

# Schritt 4: Validierung OK ‚Üí Schreiben
Thought: Validation erfolgreich, ich schreibe die Datei
Action: {{"method": "write_file", "params": {{"path": "...", "content": "..."}}}}

# Schritt 5: Fertig
Thought: Aufgabe abgeschlossen
Final Answer: Datei 'models/user.py' wurde erfolgreich erstellt mit Kontext aus __init__.py und validators.py.
```

WICHTIG:
- Nur EINE Action pro Runde
- Warte auf Observation bevor du fortf√§hrst
- Nutze validation_result aus Observation f√ºr Entscheidungen
"""


# -----------------------------------------------------------------------------
# Tool-Call Helper
# -----------------------------------------------------------------------------
_mcp = _SharedMCPClient()

def call_tool(method: str, params: Optional[dict] = None, timeout: int = 300) -> dict:
    """RPC-Call zum MCP-Server (delegiert an agent.shared.mcp_client)."""
    return _mcp.call_sync(method, params, timeout=timeout)


def inception_ready() -> Tuple[bool, str]:
    """Pr√ºft ob Inception/implement_feature verf√ºgbar ist."""
    probe = call_tool("inception_health", {})
    if isinstance(probe, dict) and not probe.get("error"):
        return True, "ok"

    ping = call_tool("implement_feature", {
        "file_paths": ["__inception_ping__.txt"],
        "instruction": "NOOP/PING ‚Äì do not write any file.",
        "dry_run": True
    })
    if isinstance(ping, dict) and not ping.get("error"):
        return True, "ok"

    err = ping.get("error") if isinstance(ping, dict) else probe
    msg = err.get("message", str(err)) if isinstance(err, dict) else str(err)
    return False, msg or "Inception nicht bereit"


# -----------------------------------------------------------------------------
# LLM Wrapper
# -----------------------------------------------------------------------------
def chat(messages: List[Dict[str, Any]], temperature: float = 1.0, token_budget: int = 2000) -> str:
    """LLM Chat mit korrekten Token-Parametern."""
    kwargs: Dict[str, Any] = {
        "model": TEXT_MODEL,
        "messages": messages,
        "temperature": temperature,
    }

    if ("gpt-5" in TEXT_MODEL) or ("gpt-4o" in TEXT_MODEL):
        kwargs["max_completion_tokens"] = token_budget
    else:
        kwargs["max_tokens"] = token_budget

    try:
        resp = client.chat.completions.create(**kwargs)
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        return f"Error: LLM API Fehler - {e}"


# -----------------------------------------------------------------------------
# Parsing-Helfer
# -----------------------------------------------------------------------------
def extract_action_json(text: str) -> Tuple[Optional[dict], Optional[str]]:
    """Extrahiert Action-JSON aus LLM-Antwort (delegiert an agent.shared.action_parser)."""
    return _shared_parse_action(text)


# -----------------------------------------------------------------------------
# Fehler-Analyse
# -----------------------------------------------------------------------------
def analyze_failure_pattern(messages: List[Dict]) -> str:
    """
    Analysiert Fehler-Pattern aus Message-Historie.

    Returns:
        Fehler-Typ (syntax/context/logic)
    """
    recent_errors = []
    for msg in messages[-5:]:  # Letzte 5 Messages
        if msg.get("role") == "user" and "Observation:" in msg.get("content", ""):
            content = msg["content"]
            if "error" in content.lower():
                recent_errors.append(content.lower())

    error_text = " ".join(recent_errors)

    if "syntax" in error_text or "parsing" in error_text:
        return "syntax"
    elif "kontext" in error_text or "nicht gefunden" in error_text or "context" in error_text:
        return "context"
    elif "validation" in error_text or "test" in error_text:
        return "validation"
    else:
        return "logic"


def get_recovery_strategy(error_type: str) -> str:
    """Gibt Recovery-Strategie basierend auf Fehler-Typ."""
    strategies = {
        "syntax": """
Syntax-Fehler erkannt. Neue Strategie:
1. Generiere kleinere Code-Abschnitte (< 50 Zeilen)
2. Validiere jeden Abschnitt einzeln
3. Nutze einfachere Konstrukte
4. Pr√ºfe Einr√ºckungen genau
""",
        "context": """
Kontext-Fehler erkannt. Neue Strategie:
1. Sammle mehr Kontext (read_file_content f√ºr √§hnliche Dateien)
2. Pr√ºfe Projektstruktur (list_agent_files)
3. Suche nach Dokumentation (search_web wenn n√∂tig)
4. Nutze recall f√ºr fr√ºhere Informationen
""",
        "validation": """
Validierungs-Fehler erkannt. Neue Strategie:
1. Pr√ºfe die Fehler-Details genau
2. √úberarbeite nur die problematischen Teile
3. Behalte funktionierende Teile bei
4. Teste inkrementell
""",
        "logic": """
Logik-Fehler erkannt. Neue Strategie:
1. Zerlege die Aufgabe in kleinere Teilschritte
2. L√∂se jeden Schritt einzeln
3. Validiere jeden Schritt vor dem n√§chsten
4. Nutze remember um Fortschritt zu speichern
"""
    }
    return strategies.get(error_type, "Versuche einen anderen Ansatz.")


# -----------------------------------------------------------------------------
# Haupt-Loop (Verbessert)
# -----------------------------------------------------------------------------
def run_developer_task(user_query: str, dest_folder: str = ".", max_steps: int = 12) -> str:
    """
    F√ºhrt Developer-Aufgabe mit verbessertem Workflow aus.

    Args:
        user_query: Nutzer-Anfrage
        dest_folder: Ziel-Ordner f√ºr Code
        max_steps: Maximale Anzahl Schritte

    Returns:
        Finale Antwort
    """
    logger.info(f"üë®‚Äçüíª D.A.V.E. v2 startet f√ºr: {user_query!r}")
    logger.info(f"   Ziel-Ordner: {dest_folder}")

    # Preflight: Inception-Check (falls erforderlich)
    if REQUIRE_INCEPTION:
        ok, why = inception_ready()
        if not ok:
            logger.error(f"Inception nicht bereit: {why}")
            return (f"Inception/implement_feature ist nicht bereit: {why}. "
                   "Bitte pr√ºfe ENV (INCEPTION_*, MCP_URL) und den Serverstart.")

    # System-Prompt mit Projekt-Kontext
    system_prompt = build_system_prompt(dest_folder)

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_query},
    ]

    failures = 0
    strategy_changed = False
    generated_code_cache = {}  # Cache f√ºr generierten Code

    for step in range(1, max_steps + 1):
        logger.info(f"‚öôÔ∏è Schritt {step}/{max_steps} (Fehler: {failures})")

        # LLM beauftragen
        reply = chat(messages, temperature=1.0, token_budget=2500)

        if not isinstance(reply, str):
            failures += 1
            messages.append({"role": "user", "content": f"Observation: {json.dumps({'error': 'Ung√ºltige LLM-Antwort'})}"})
            continue

        messages.append({"role": "assistant", "content": reply})
        logger.debug(f"üß† LLM:\n{reply}")

        # Sofortiger Abschluss?
        if "Final Answer:" in reply:
            final = reply.split("Final Answer:", 1)[1].strip()
            logger.info("‚úÖ Aufgabe abgeschlossen.")

            # Learning Entry
            call_tool("log_learning_entry", {
                "goal": user_query,
                "outcome": "success",
                "details": {
                    "final_step_count": step,
                    "failures": failures,
                    "strategy_changed": strategy_changed,
                    "dest_folder": dest_folder
                },
                "learning": "Entwicklung mit verbessertem Agent erfolgreich abgeschlossen."
            })
            return final

        # Action extrahieren
        action, perr = extract_action_json(reply)
        if perr or not action:
            failures += 1
            logger.warning(f"Keine g√ºltige Action erkannt: {perr}")
            messages.append({"role": "user", "content": f"Observation: {json.dumps({'error': perr or 'no_action'})}"})

            # Fehler-Recovery
            if failures >= 2 and not strategy_changed:
                error_type = analyze_failure_pattern(messages)
                strategy = get_recovery_strategy(error_type)
                logger.info(f"üí° Wechsle Strategie (Fehler-Typ: {error_type})")
                messages.append({"role": "user", "content": strategy})
                strategy_changed = True
                failures = 0

            continue

        method = action.get("method")
        params = action.get("params", {}) if isinstance(action.get("params"), dict) else {}

        # Tool-Whitelist pr√ºfen
        if method not in ALLOWED_TOOLS:
            failures += 1
            logger.warning(f"Tool '{method}' nicht erlaubt.")
            error_obs = {
                'error': f'Tool nicht erlaubt: {method}',
                'allowed_tools': ALLOWED_TOOLS,
                'hint': 'Nutze eines der erlaubten Tools'
            }
            messages.append({"role": "user", "content": f"Observation: {json.dumps(error_obs)}"})
            continue

        # Intelligente Context-Files f√ºr implement_feature
        if method == "implement_feature" and "context_files" not in params:
            file_paths = params.get("file_paths", [])
            if isinstance(file_paths, str):
                file_paths = [file_paths]

            if file_paths:
                target_file = file_paths[0]
                context_files = find_related_files(dest_folder, target_file, max_files=3)
                if context_files:
                    params["context_files"] = context_files
                    logger.info(f"üìö Auto-Context hinzugef√ºgt: {context_files}")

        # Tool ausf√ºhren
        logger.info(f"üîß F√ºhre aus: {method}({list(params.keys())})")
        obs = call_tool(method, params, timeout=420)

        # Fehler-Handling
        if isinstance(obs, dict) and obs.get("error"):
            failures += 1
            err_msg = str(obs.get("error"))
            logger.error(f"Tool-Fehler: {err_msg}")

            messages.append({"role": "user", "content": f"Observation: {json.dumps(obs)}"})

            # Fehler-Recovery
            if failures >= 2 and not strategy_changed:
                error_type = analyze_failure_pattern(messages)
                strategy = get_recovery_strategy(error_type)
                logger.info(f"üí° Wechsle Strategie (Fehler-Typ: {error_type})")
                messages.append({"role": "user", "content": strategy})
                strategy_changed = True
                failures = 0

            continue

        # Spezial-Handling f√ºr Code-Generierung
        if method in ["implement_feature", "generate_and_integrate"] and not obs.get("error"):
            generated = obs.get("generated_code")
            file_path = obs.get("file_path") or (
                params.get("file_paths", [None])[0] if isinstance(params.get("file_paths"), list)
                else params.get("dest_folder", "output.py")
            )

            if generated and file_path:
                logger.info(f"üìù Code generiert f√ºr: {file_path}")

                # CODE-VALIDIERUNG (KRITISCH!)
                validation = validate_code(generated, file_path, dest_folder)

                # Cache Code f√ºr sp√§teres Schreiben
                generated_code_cache[file_path] = generated

                # Erweiterte Observation mit Validation
                obs["validation"] = validation
                obs["file_path"] = file_path
                obs["ready_to_write"] = validation["valid"]

                if validation["valid"]:
                    obs["next_step"] = f"Code validiert! Nutze write_file mit path='{file_path}' um zu speichern."
                    logger.info(f"‚úÖ Validation erfolgreich f√ºr {file_path}")
                else:
                    obs["next_step"] = f"Validation fehlgeschlagen. √úberarbeite den Code basierend auf errors."
                    logger.warning(f"‚ùå Validation fehlgeschlagen: {validation['errors']}")

                # Warnung auch ausgeben
                if validation["warnings"]:
                    obs["validation_warnings"] = validation["warnings"]

        # Spezial-Handling f√ºr write_file (Code aus Cache holen)
        if method == "write_file":
            path = params.get("path")
            content = params.get("content")

            # Wenn kein content angegeben, aus Cache holen
            if not content and path and path in generated_code_cache:
                logger.info(f"üì• Hole Code aus Cache f√ºr: {path}")
                content = generated_code_cache[path]
                # Nochmal Tool mit content aufrufen
                obs = call_tool("write_file", {"path": path, "content": content}, timeout=30)

                if not obs.get("error"):
                    logger.info(f"‚úÖ Datei geschrieben: {path}")
                    # Cache leeren
                    del generated_code_cache[path]

        # Observation zur√ºckgeben
        messages.append({"role": "user", "content": f"Observation: {json.dumps(obs, ensure_ascii=False)[:1000]}"})

        # Bei Erfolg: Failures zur√ºcksetzen
        if not obs.get("error"):
            failures = 0

        # Zu viele Fehler?
        if failures >= 4:
            logger.error("Zu viele Fehlversuche; breche ab.")
            call_tool("log_learning_entry", {
                "goal": user_query,
                "outcome": "failure_max_retries",
                "details": {
                    "error": "Max retries exceeded",
                    "final_step": step,
                    "dest_folder": dest_folder
                },
                "learning": "Zu viele Fehler, m√∂glicherweise ist die Aufgabe zu komplex."
            })
            return "‚ùå Konnte Aufgabe nicht abschlie√üen (zu viele Fehler). Details wurden geloggt."

    # Max Steps erreicht
    logger.warning("‚ö†Ô∏è Maximale Anzahl an Schritten erreicht")
    call_tool("log_learning_entry", {
        "goal": user_query,
        "outcome": "timeout",
        "details": {"final_step": max_steps, "dest_folder": dest_folder},
        "learning": "Max steps erreicht, Aufgabe evtl. zu komplex oder mehr Schritte n√∂tig."
    })
    return "‚ö†Ô∏è Maximale Anzahl an Schritten erreicht, ohne finale Antwort."


# -----------------------------------------------------------------------------
# Async Wrapper f√ºr Integration mit main_dispatcher
# -----------------------------------------------------------------------------
class DeveloperAgentV2:
    """
    Async-kompatible Wrapper-Klasse f√ºr developer_agent_v2.

    Erm√∂glicht Integration mit main_dispatcher.py, der async agents erwartet.
    """
    def __init__(self, tools_description_string: str, dest_folder: str = ".", max_steps: int = 12):
        self.tools_description = tools_description_string
        self.dest_folder = dest_folder
        self.max_steps = max_steps

    async def run(self, query: str) -> str:
        """
        F√ºhrt den Developer-Agenten aus (async wrapper).

        Args:
            query: Entwicklungsaufgabe

        Returns:
            Finale Antwort des Agenten
        """
        import asyncio
        # F√ºhre sync Funktion in thread pool aus
        result = await asyncio.to_thread(
            run_developer_task,
            query,
            dest_folder=self.dest_folder,
            max_steps=self.max_steps
        )
        return result


# -----------------------------------------------------------------------------
# CLI
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="D.A.V.E. v2 - Verbesserter Developer Agent")
    parser.add_argument("query", nargs="+", help="Entwicklungsaufgabe")
    parser.add_argument("--folder", "-f", default=".", help="Ziel-Ordner (default: .)")
    parser.add_argument("--steps", "-s", type=int, default=12, help="Max Schritte (default: 12)")

    args = parser.parse_args()

    query = " ".join(args.query)
    result = run_developer_task(query, dest_folder=args.folder, max_steps=args.steps)

    print("\n" + "="*80)
    print("üí° FINALE ANTWORT DES DEVELOPER-AGENTEN (v2):")
    print("="*80)
    print(textwrap.fill(result, width=80))
    print("="*80)
